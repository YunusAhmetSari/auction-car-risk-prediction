{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Datenmanipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualisierung\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
        "\n",
        "# Imbalanced-learn\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Daten laden\n",
        "from core.data import clean_data, load_competition_from_kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Gather Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Daten herunterladen (Kaggle Competition)\n",
        "competition_name = \"DontGetKicked\"\n",
        "destination = \"../data/raw\"\n",
        "\n",
        "files = load_competition_from_kaggle(\n",
        "    competition_name=competition_name,\n",
        "    destination=destination,\n",
        ")\n",
        "\n",
        "# Trainingsdatei finden\n",
        "train_file = [f for f in files if \"training\" in f.lower()][0]\n",
        "\n",
        "# Einlesen der Daten\n",
        "df = pd.read_csv(\"/\".join([destination, competition_name, train_file]))\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explorative Datenanalayse (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Understand Data**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Erste Übersicht über die Daten (Dimensions, Beschreibung, Duplikate)\n",
        "display(\n",
        "    \"Shape\",\n",
        "    df.shape,\n",
        "    \"Description\",\n",
        "    df.describe().round(2).T,\n",
        "    \"Duplicates\",\n",
        "    df.duplicated().sum(),\n",
        ")\n",
        "\n",
        "# Übersicht über die Spalten (Datentypen, fehlende Werte, eindeutige Werte, Beispielwerte)\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        \"Data Types\": df.dtypes,\n",
        "        \"Missing Values\": df.isnull().sum(),\n",
        "        \"Unique Values\": df.nunique(),\n",
        "        \"Sample Values\": [df[col].sample(3, random_state=42).tolist() for col in df.columns],\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Outliers Detection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kategoriale Features: Verteilung nach Zielvariable\n",
        "categorical_features = [\n",
        "    \"Auction\",\n",
        "    \"Transmission\",\n",
        "    \"WheelTypeID\",\n",
        "    \"WheelType\",\n",
        "    \"Nationality\",\n",
        "    \"TopThreeAmericanName\",\n",
        "    \"PRIMEUNIT\",\n",
        "    \"AUCGUART\",\n",
        "    \"IsOnlineSale\",\n",
        "]\n",
        "\n",
        "for categorical_feature in categorical_features:\n",
        "    # Füllen der fehlenden Werte mit \"Missing\"\n",
        "    df_col = df[categorical_feature].fillna(\"Missing\")\n",
        "\n",
        "    # Kreuztabelle\n",
        "    print(f\"\\n=== {categorical_feature} ===\")\n",
        "    print(pd.crosstab(df_col, df[\"IsBadBuy\"]))\n",
        "\n",
        "    # Visualisierung\n",
        "    plt.figure(figsize=(16, 6))\n",
        "    palette = [\"#009292\", \"#074650\"]\n",
        "    sns.countplot(\n",
        "        x=df_col,\n",
        "        data=df,\n",
        "        hue=\"IsBadBuy\",\n",
        "        stat=\"proportion\",\n",
        "        order=df_col.value_counts().index,\n",
        "        palette=palette,\n",
        "    )\n",
        "    plt.title(f\"Distribution of {categorical_feature}\")\n",
        "    plt.xlabel(None)\n",
        "    plt.ylabel(\"Proportion\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hochkardinalen kategoriale Features: Verteilung nach Zielvariable\n",
        "high_cardinality_categorical_features = [\n",
        "    \"Make\", \n",
        "    \"Color\", \n",
        "    \"Size\", \n",
        "    \"VNST\", \n",
        "    \"Model\", \n",
        "    \"Trim\", \n",
        "    \"SubModel\", \n",
        "    \"BYRNO\", \n",
        "    \"VNZIP1\"]\n",
        "top_n = 10\n",
        "\n",
        "for categorical_feature in high_cardinality_categorical_features:\n",
        "    # Füllen der fehlenden Werte mit \"Missing\"\n",
        "    df_col = df[categorical_feature].astype(\"object\").fillna(\"Missing\")\n",
        "\n",
        "    # Top-N-Kategorien behalten, Rest als \"Other\" zusammenfassen\n",
        "    top_n_categories = df_col.value_counts().head(top_n).index\n",
        "    df_col = df_col.where(df_col.isin(top_n_categories), other=\"Other\")\n",
        "\n",
        "    # Kreuztabelle\n",
        "    print(pd.crosstab(df_col, df[\"IsBadBuy\"]))\n",
        "\n",
        "    # Visualisierung\n",
        "    plt.figure(figsize=(16, 6))\n",
        "    palette = [\"#009292\", \"#074650\"]\n",
        "    sns.countplot(\n",
        "        x=df_col,\n",
        "        data=df,\n",
        "        hue=\"IsBadBuy\",\n",
        "        stat=\"proportion\",\n",
        "        order=df_col.value_counts().index,\n",
        "        palette=palette,\n",
        "    )\n",
        "    plt.title(f\"Distribution of {categorical_feature} (Top {top_n} + Other)\")\n",
        "    plt.xlabel(None)\n",
        "    plt.ylabel(\"Proportion\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Numerische Features: Verteilung nach Zielvariable\n",
        "numerical_features = [\n",
        "    \"MMRAcquisitionAuctionAveragePrice\",\n",
        "    \"MMRAcquisitionAuctionCleanPrice\",\n",
        "    \"MMRAcquisitionRetailAveragePrice\",\n",
        "    \"MMRAcquisitonRetailCleanPrice\",\n",
        "    \"MMRCurrentAuctionAveragePrice\",\n",
        "    \"MMRCurrentAuctionCleanPrice\",\n",
        "    \"MMRCurrentRetailAveragePrice\",\n",
        "    \"MMRCurrentRetailCleanPrice\",\n",
        "    \"VehBCost\",\n",
        "    \"WarrantyCost\",\n",
        "    \"VehOdo\",\n",
        "    \"VehicleAge\",\n",
        "]\n",
        "\n",
        "for numerical_feature in numerical_features:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
        "    palette = [\"#009292\", \"#074650\"]\n",
        "\n",
        "    sns.histplot(\n",
        "        x=df[numerical_feature], \n",
        "        kde=True, ax=axes[0], \n",
        "        color=palette[0]\n",
        "    )\n",
        "    sns.boxplot(\n",
        "        data=df, \n",
        "        x=\"IsBadBuy\", \n",
        "        y=numerical_feature, \n",
        "        hue=\"IsBadBuy\", \n",
        "        ax=axes[1], \n",
        "        palette=palette\n",
        "    )\n",
        "    axes[0].set_title(f\"Histogram of {numerical_feature}\")\n",
        "    axes[1].set_title(f\"Boxplot of {numerical_feature}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Korrelationen\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(df.corr(numeric_only=True), annot=True, cmap=\"viridis\", center=0, fmt=\".2f\")\n",
        "plt.title(\"Korrelationsmatrix (numerische Features)\")\n",
        "plt.show()\n",
        "\n",
        "# Zielverteilung\n",
        "print(\"Verteilung des Targets (gesamt):\")\n",
        "print(df[\"IsBadBuy\"].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Train-Test-Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/Test-Split (stratifiziert wegen Klassenungleichgewicht)\n",
        "target_col = \"IsBadBuy\"\n",
        "features = df.drop(columns=target_col)\n",
        "target = df[target_col]\n",
        "\n",
        "features_train, features_test, target_train, target_test = train_test_split(\n",
        "    features,\n",
        "    target,\n",
        "    random_state=42,\n",
        "    test_size=0.1,\n",
        "    stratify=target\n",
        ")\n",
        "\n",
        "# Überprüfung des Train-Test-Splits\n",
        "print(\"Dimensionen der Trainingsdaten (Features):\", features_train.shape)\n",
        "print(\"Dimensionen der Testdaten (Features):\", features_test.shape)\n",
        "print(\"\\nVerteilung des Targets im Trainings-Set:\")\n",
        "print(target_train.value_counts(normalize=True))\n",
        "print(\"\\nVerteilung des Targets im Test-Set:\")\n",
        "print(target_test.value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Datatype Transformation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wrapper für Pipeline\n",
        "def apply_clean(X: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Wrapper to make clean_data usable in sklearn pipelines.\"\"\"\n",
        "    return clean_data(X)\n",
        "\n",
        "clean_step = FunctionTransformer(apply_clean, validate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bereinigung und Datentypkonvertierung der Trainings- undd Testdaten\n",
        "features_train_clean = apply_clean(features_train)\n",
        "features_test_clean = apply_clean(features_test)\n",
        "\n",
        "# Vergleich Datentypkonvertierung vorher und nachher\n",
        "dtypes_before = features_train.dtypes\n",
        "dtypes_after = features_train_clean.dtypes\n",
        "dtype_comparison = pd.DataFrame({\"dtypes_before\": dtypes_before, \"dtypes_after\": dtypes_after})\n",
        "display(dtype_comparison)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Data Imputation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Features trennen in numerische und kateogrische Spalten\n",
        "numeric_features = features_train_clean.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = features_train_clean.select_dtypes(include=\"object\").columns.tolist()\n",
        "datetime_features = features_train_clean.select_dtypes(include=\"datetime\").columns.tolist()\n",
        "\n",
        "# Auftrennung der kategorischen Spalten\n",
        "mode_cols = [\"Transmission\", \"IsOnlineSale\"]\n",
        "cat_mode_cols = [col for col in categorical_features if col in mode_cols]\n",
        "cat_missing_cols = [col for col in categorical_features if col not in mode_cols]\n",
        "\n",
        "numeric_transformer = SimpleImputer(strategy=\"median\")\n",
        "\n",
        "categorical_transformer_mode = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer_mode\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"encoder_mode\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "categorical_transformer_missing = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer_missing\", SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")),\n",
        "        (\"encoder_missing\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"cat_mode\", categorical_transformer_mode, cat_mode_cols),\n",
        "        (\"cat_missing\", categorical_transformer_missing, cat_missing_cols),\n",
        "        (\"date\", \"passthrough\", datetime_features)\n",
        "    ],\n",
        "    remainder=\"drop\",\n",
        "    verbose_feature_names_out=False\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "# Vorverarbeitung der Trainingsdaten und Testdaten mit dem Preprocessor\n",
        "features_train_preprocessed = preprocessor.fit_transform(features_train_clean)\n",
        "features_test_preprocessed = preprocessor.transform(features_test_clean)\n",
        "\n",
        "# Vergleich fehlende Wete vor und nach Imputation\n",
        "print(\"Fehlende Werte vor Preprocessing\", features_train_clean.isna().sum().sum())\n",
        "print(\"Fehlende Werte nach Preprocessing\",features_train_preprocessed.isna().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resampling des Trainingssets (RandomUnderSampler)\n",
        "resampler = RandomUnderSampler(random_state=42)\n",
        "\n",
        "features_train_resampled, target_train_resampled = resampler.fit_resample(features_train_preprocessed, target_train)\n",
        "\n",
        "print(\"Verteilung des Targets vor Resampling:\")\n",
        "print(target_train.value_counts(normalize=True))\n",
        "print(\"\\nVerteilung des Targets nach Resampling:\")\n",
        "print(target_train_resampled.value_counts(normalize=True))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
